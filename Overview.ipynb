{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray on Databricks Training\n",
    "\n",
    "*This material is taken from the Anyscale Academy and has been modified to run on Databricks.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Help\n",
    "\n",
    "For Ray related technical questions, reach out to #help-ray on Slack\n",
    "\n",
    "For account related questions, reach out to the #ray-gtm team\n",
    "\n",
    "### Engineering\n",
    "- Nitin Wagh (nitin.wagh@databricks.com)\n",
    "- Mahesh Venkatachalam (mahesh.venkatachalam@databricks.com) \n",
    "- Ben Wilson (benjamin.wilson@databricks.com)\n",
    "\n",
    "### Field Engineering\n",
    "- Stephen Offer  (stephen.offer@databricks.com)\n",
    "- Puneet Jain (puneet.jain@databricks.com) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Tutorials Are Right for Me?\n",
    "\n",
    "Here is a recommended reading list, based on your interests:\n",
    "\n",
    "If you are a developer who is new to Ray, start with [_Ray Crash Course_](#user-content-ray-crash-course), then [_Advanced Ray_](#user-content-advanced-ray).\n",
    "\n",
    "If you are a developer who is experienced with Ray, go straight to [_Advanced Ray_](#user-content-advanced-ray).\n",
    "\n",
    "If you are either a developer or a data scientist interested in one of the following topics:\n",
    "\n",
    "* Reinforcement Learning: see [_Ray RLlib_](#user-content-ray-rllib)\n",
    "* Hyperparameter Tuning: see [_Ray Tune_](#user-content-ray-tune)\n",
    "* Accelerated model training with PyTorch: see [_Ray Train_](#user-content-ray-train)\n",
    "* Model serving: see [_Ray Serve_](#user-content-ray-serve)\n",
    "\n",
    "If you are a _DevOps_ engineer interested in managing Ray clusters, see [_Ray Cluster Launcher_](#user-content-ray-cluster-launcher)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Ray Set Up on a Databricks Cluster\n",
    "\n",
    "To get started with this course, please create a cluster with this configuration:\n",
    "\n",
    "- Ray on Databricks currently only supports Single-Access mode clusters\n",
    "- The init functions in this course are set to run with 2 worker nodes and 4 CPUs per node, so select a cluster with at least 2 workers and 4 CPUs available per node.\n",
    "- Ray will be included in the Databricks Machine Learning Runtime (MLR) in Q1 of 2024, but if not using the latest MLR, please install using the Libraries panel, selecting PyPI as the source and installing 'ray[all]'\n",
    "\n",
    "This cluster can be reused for all sections of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Descriptions\n",
    "\n",
    "The rest of this notebook describes each tutorial in more depth, with links to all the lesson notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "**Directory:** `reference`\n",
    "\n",
    "The notebooks here provide reference material, like general tips and tricks, how to get help, and troubleshooting issues.\n",
    "\n",
    "* [Troubleshooting, Tips, and Tricks](reference/Troubleshooting-Tips-Tricks.ipynb): How to troubleshoot common problems and other useful tips and tricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Crash Course\n",
    "\n",
    "**Directory:** `ray-crash-course`\n",
    "\n",
    "**Audience:** You are a developer who wants a fast introduction to the core Ray API. The first two lessons cover the essential parts of the Ray API for _tasks_ and _actors_. The rest of the lessons explore the origin and goals for Ray, Ray replacement versions of several popular multiprocessing APIs, a Ray _parallel iterator_ API, and working with Ray clusters using the `ray` command-line interface (CLI).\n",
    "\n",
    "Experienced developers should consider the _Advanced Ray_ tutorial. Data scientists may wish to skip to one of the _Ray RLlib_, _Ray Tune_, _Ray SGD_, or _Ray Serve_ tutorials.\n",
    "\n",
    "This is the place to start if you are new to Ray and you plan to use it to scale Python applications to a cluster. Data scientists working with Ray-based toolkits, like _RLlib_, don't need this knowledge to get started.\n",
    "\n",
    "The _crash course_ is intended to focus on learning the core API as quickly as possible, but using nontrivial examples. In contrast, the _Advanced Ray_ tutorial explores more advanced API usage, profiling and debugging applications, and how Ray works behind the scenes.\n",
    "\n",
    "\n",
    "| #  | Lesson (Notebook)                                         | Description                               |\n",
    "| :- | :-------------------------------------------------------- | :---------------------------------------- |\n",
    "| 00 | [Overview](ray-crash-course/00-Ray-Crash-Course-Overview.ipynb)            | A _table of contents_ for this tutorial.  |\n",
    "| 01 | [Ray Tasks](ray-crash-course/01-Ray-Tasks.ipynb)                           | Understanding how Ray converts normal Python functions into distributed _stateless tasks_. |\n",
    "| 02 | [Ray Actors](ray-crash-course/02-Ray-Actors.ipynb)                         | Understanding how Ray converts normal Python classes into distributed, _stateful actors_.  |\n",
    "| 03 | [Ray Actors](ray-crash-course/02-Ray-Objects.ipynb)                         | Understanding Ray's distributed obect store  |\n",
    "| 04 | [Exploring Ray API Calls](ray-crash-course/04-Exploring-Ray-API-Calls.ipynb) | The Ray API has other API calls for more advanced scenarios, which are surveyed in this optional lesson. Keyword arguments you can pass to the API calls already learned are explored. |\n",
    "| 05 | [Running Ray Clusters](ray-crash-course/05-Running-Ray-Clusters.ipynb)     | A brief look at the Ray CLI commands for running Ray clusters. |\n",
    "| 06 | [Using Ray's Multiprocess Pool Library](ray-crash-course/06-Ray-multi-pool.ipynb)     | A brief look how you use Ray's dropin replacement for Multiprocess pool library. |\n",
    "\n",
    "Once you've completed this tutorial, go through _Advanced Ray_ or explore one of the ML-related library tutorials, in any order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Ray\n",
    "\n",
    "Directory: `advanced-ray`\n",
    "\n",
    "Go through the [_Crash Course_](#ray-crash-course) first if you are new to Ray. This tutorial provides a deeper dive into Ray tasks and actors, such as profiling and debugging applications. It also surveys the rest of the core API.\n",
    "\n",
    "| #  | Lesson (Notebook)                                         | Description                               |\n",
    "| :- | :-------------------------------------------------------- | :---------------------------------------- |\n",
    "| 00 | [Overview](advanced-ray/00-Advanced-Ray-Overview.ipynb)   | A _table of contents_ for this tutorial.  |\n",
    "| 01 | [Ray Tasks Revisited](advanced-ray/01-Ray-Tasks-Revisited.ipynb) | More exploration of `ray.wait()` usage patterns, task dependencies and their management, and task profiling techniques. |\n",
    "| 02 | [Ray Actors Revisited](advanced-ray/02-Ray-Actors-Revisited.ipynb) | A more in-depth look at actor characteristics and profiling actor performance using the _Ray Dashboard_. |\n",
    "| 03 | [Ray Internals](advanced-ray/03-Ray-Internals.ipynb) | Explores the architecture of Ray, task scheduling, the Object Store, etc. |\n",
    "\n",
    "In addition, exercise solutions for this tutorial can be found [here](advanced-ray/solutions/Advanced-Ray-Solutions.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray RLlib\n",
    "\n",
    "Directory: `ray-rllib`\n",
    "\n",
    "_Ray RLlib_ is Ray's system for _reinforcement learning_. This tutorial begins with a \"crash course\" in RL concepts. It then explores several of the commonly-used algorithms and approaches for different applications.\n",
    "\n",
    "Because of the breadth of RL this tutorial is divided into several sections.\n",
    "\n",
    "> **Tip:** See [Ray RLlib Overview](ray-rllib/00-Ray-RLlib-Overview.ipynb) for a suggested _learning plan_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Sections\n",
    "\n",
    "Because of the breadth of RL this tutorial is divided into several sections. See below for a recommended _learning plan_.\n",
    "\n",
    "### Introduction to Reinforcement Learning and RLlib\n",
    "\n",
    "|    | Lesson | Description |\n",
    "| :- | :----- | :---------- |\n",
    "| 00 | [Ray RLlib Overview](ray-rllib/00-Ray-RLlib-Overview.ipynb) | Overview of this tutorial, including all the sections. |\n",
    "| 01 | [Introduction to Reinforcement Learning](ray-rllib/01-Introduction-to-Reinforcement-Learning.ipynb) | A quick introduction to the concepts of reinforcement learning. You can skim or skip this lesson if you already understand RL concepts. |\n",
    "| 02 | [Introduction to RLlib](ray-rllib/02-Introduction-to-RLlib.ipynb) | An overview of RLlib, its goals and the capabilities it provides. |\n",
    "|    | [RL References](ray-rllib/References-Reinforcement-Learning.ipynb) | References on reinforcement learning. |\n",
    "\n",
    "Exercise solutions for this introduction can be found [here](ray-rllib/solutions/Ray-RLlib-Solutions.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Armed Bandits\n",
    "\n",
    "_Multi-Armed Bandits_ (MABs) are a special kind of RL problem that have broad and growing applications. They are also an excellent platform for investigating the important _exploitation vs. exploration tradeoff_ at the heart of RL. The term _multi-armed bandit_ is inspired by the slot machines in casinos, so called _one-armed bandits_, but where a machine might have more than one arm. \n",
    "\n",
    "|    | Lesson | Description |\n",
    "| :- | :----- | :---------- |\n",
    "| 00 | [Multi-Armed-Bandits Overview](ray-rllib/multi-armed-bandits/00-Multi-Armed-Bandits-Overview.ipynb) | Overview of this set of lessons. |\n",
    "| 01 | [Introduction to Multi-Armed Bandits](ray-rllib/multi-armed-bandits/01-Introduction-to-Multi-Armed-Bandits.ipynb) | A quick introduction to the concepts of multi-armed bandits (MABs) and how they fit in the spectrum of RL problems. |\n",
    "| 02 | [Exploration vs. Exploitation Strategies](ray-rllib/multi-armed-bandits/02-Exploration-vs-Exploitation-Strategies.ipynb) | A deeper look at algorithms that balance exploration vs. exploitation, the key challenge for efficient solutions. Much of this material is technical and can be skipped in a first reading, but skim the first part of this lesson at least. |\n",
    "| 03 | [Simple Multi-Armed Bandit](ray-rllib/multi-armed-bandits/03-Simple-Multi-Armed-Bandit.ipynb) | A simple example of a multi-armed bandit to illustrate the core ideas. |\n",
    "| 04 | [Linear Upper Confidence Bound](ray-rllib/multi-armed-bandits/04-Linear-Upper-Confidence-Bound.ipynb) | One popular algorithm for exploration vs. exploitation is _Upper Confidence Bound_. This lesson shows how to use a linear version in RLlib. |\n",
    "| 05 | [Linear Thompson Sampling](ray-rllib/multi-armed-bandits/05-Linear-Thompson-Sampling.ipynb) | Another popular algorithm for exploration vs. exploitation is _Thompson Sampling_. This lesson shows how to use a linear version in RLlib. |\n",
    "| 06 | [Market Example](ray-rllib/multi-armed-bandits/06-Market-Example.ipynb) | A simplified real-world example of MABs, finding the optimal stock and bond investment strategy. |\n",
    "\n",
    "Exercise solutions for this bandits segment of the tutorial can be found [here](ray-rllib/multi-armed-bandits/solutions/Multi-Armed-Bandits-Solutions.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Reinforcement Learning and RLlib\n",
    "\n",
    "This section dives into more details about RL and using RLlib. It is best studied after going through the MAB material.\n",
    "\n",
    "|    | Lesson | Description |\n",
    "| :- | :----- | :---------- |\n",
    "| 00 | [Explore RLlib Overview](ray-rllib/explore-rllib/00-Explore-RLlib-Overview.ipynb) | Overview of this set of lessons. |\n",
    "| 01 | [Application - Cart Pole](ray-rllib/explore-rllib/01-Application-Cart-Pole.ipynb) | The best starting place for learning how to use RL, in this case to train a moving car to balance a vertical pole. Based on the `CartPole-v1` environment from OpenAI Gym, combined with RLlib. |\n",
    "| 02 | [Application: Bipedal Walker](ray-rllib/explore-rllib/02-Bipedal-Walker.ipynb) | Train a two-legged robot simulator. This is an optional lesson, due to the longer compute times required, but fun to try. |\n",
    "| 03 | [Custom Environments and Reward Shaping](ray-rllib/explore-rllib/03-Custom-Environments-Reward-Shaping.ipynb) | How to customize environments and rewards for your applications. |\n",
    "\n",
    "Some additional examples you might explore can be found in the `extras` folder:\n",
    "\n",
    "| Lesson | Description |\n",
    "| :----- | :---------- |\n",
    "| [Extra: Application - Mountain Car](ray-rllib/explore-rllib/extras/Extra-Application-Mountain-Car.ipynb) | Based on the `MountainCar-v0` environment from OpenAI Gym. |\n",
    "| [Extra: Application - Taxi](ray-rllib/explore-rllib/extras/Extra-Application-Taxi.ipynb) | Based on the `Taxi-v3` environment from OpenAI Gym. |\n",
    "| [Extra: Application - Frozen Lake](ray-rllib/explore-rllib/extras/Extra-Application-Frozen-Lake.ipynb) | Based on the `FrozenLake-v0` environment from OpenAI Gym. |\n",
    "\n",
    "In addition, exercise solutions for this \"exploration\" section of the tutorial can be found [here](ray-rllib/explore-rllib/solutions/Ray-RLlib-Solutions.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecSys: Recommender System\n",
    "\n",
    "This section applies RL to the problem of building a recommender system, a state-of-the-art technique that addresses many of the limitations of older approaches.\n",
    "\n",
    "|    | Lesson | Description |\n",
    "| :- | :----- | :---------- |\n",
    "| 00 | [RecSys: Recommender System Overview](ray-rllib/recsys/00-RecSys-Overview.ipynb) | Overview of this set of lessons. |\n",
    "| 01 | [Recsys: Recommender System](ray-rllib/recsys/01-Recsys.ipynb) | An example that builds a recommender system using reinforcement learning. |\n",
    "\n",
    "The [Custom Environments and Reward Shaping](ray-rllib/explore-rllib/03-Custom-Environments-Reward-Shaping.ipynb) lesson from _Explore RLlib_ might be useful background for this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Tune\n",
    "\n",
    "Directory: `ray-tune`\n",
    "\n",
    "_Ray Tune_ is Ray's system for _hyperparameter tuning_. This tutorial starts with an explanation of what hyperparameter tuning is for and the performances challenges doing it for many applications. Then the tutorial explores how to use _Tune_, how it integrates with several popular ML frameworks, and the algorithms supported in _Tune_.\n",
    "\n",
    "|     | Lesson | Description |\n",
    "| :-- | :----- | :---------- |\n",
    "| 00  | [Ray Tune Overview](ray-tune/00-Ray-Tune-Overview.ipynb) | Overview of this tutorial. |\n",
    "| 01  | [Understanding Hyperparameter Tuning](ray-tune/01-Understanding-Hyperparameter-Tuning.ipynb) | An explanation of hyperparameters vs. parameters. Also, some definitions and terms, along with diagrams showing the lifecycle of a trial. |\n",
    "| 02  | [Ray Tune Warm Up](ray-tune/02-Ray-Tune-Warmup.ipynb) | Getting Started of Ray Tune Steps 1-2. |\n",
    "| 03  | [Ray Tune with Sklearn](ray-tune/03-Ray-Tune-with-Sklearn.ipynb) | More exploration of the Tune API, using Tune's replacements for GridSearchCV and RandomizedSearchCV example. |\n",
    "| 04  | [Ray Tune with MNIST](ray-tune/04-Ray-Tune-with-MNIST.ipynb) | More exploration of the Tune API, using an MNIST example. |\n",
    "| 05  | [Search Algos and Schedulers](ray-tune/05-Search-Algos-and-Schedulers.ipynb) | Understanding the concepts of search algorithms and schedulers, again using an MNIST example. |\n",
    "| 06  | [End-to-End XGBoost with Ray Tune](ray-tune/06-Ray-Tune-and-XGBoost.ipynb) | An end-to-end example of using XGBoost and Ray Tune |\n",
    "| 07  | [Ray Tune with TuneSearchCV and XGBoost](ray-tune/06-Ray-Tune-with-TuneSearchCV.ipynb) | A real life example of using Tune's drop-in replacements for HPO with XGBoost. With only few lines you can replace your existing sci-kit learn hyperparameter search with Tune's distributed HPO |\n",
    "| 08    | [Hyperparameter Tuning References](ray-tune/References-Hyperparameter-Tuning.ipynb) | Read through these references for hyperparameter tuning. |\n",
    "\n",
    "In addition, exercise solutions for this tutorial can be found in the `solutions` directory.\n",
    "\n",
    "For other, earlier tutorials that use Tune,  \n",
    " * [code examples](https://github.com/ray-project/tune-sklearn/tree/master/examples) from the Ray GitHub\n",
    " * [tune examples](https://docs.ray.io/en/latest/tune/examples/index.html) in the Ray Tune documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Train\n",
    "\n",
    "`Ray Train` is a tool to more easily exploit a cluster to perform training with _Stochastic Gradient Descent_ using PyTorch, horovod, and TensorFlow.\n",
    "\n",
    "\n",
    "|     | Lesson | Description |\n",
    "| :-- | :----- | :---------- |\n",
    "| 00  | [Ray Train Overview](ray-train/00-Ray-Train-Overview.ipynb) | Overview of this tutorial. |\n",
    "| 01  | [Ray Train Quickstart ](ray-train/01-Ray-Train-Quickstart.ipynb) | A quick start on PyTorch training on single worker. |\n",
    "| 02  | [Ray Train Quickstart Distributed](ray-train/02-Ray-Train-Quickstart-Distributed.ipynb) |A quick start on PyTorch Distributed training on multiple workers . |\n",
    "| 03  | [Ray Train with PyTorch](ray-train/03-Ray-Train-with-PyTorch.ipynb) | Use Ray Train Distributed API to train a linear model |\n",
    "| 04  | [Ray Train with PyTorch and FashionMNSIT](ray-train/04-Ray-Train-with-PyTorch-FashionMNIST.ipynb) | Use Ray Train Distributed API to train a NN for FashionMNIST |\n",
    "|     | [Ray Train Examples](https://docs.ray.io/en/latest/train/examples.html) | Explore examples for Ray Train with PyTorch, TensorFlow, and Horvod. |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
